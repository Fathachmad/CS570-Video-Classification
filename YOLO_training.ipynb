{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.15 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.12 ðŸš€ Python-3.10.12 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 7952MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/TOT.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18\n",
      "Overriding model.yaml nc=80 with nc=48\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    760672  ultralytics.nn.modules.head.Detect           [48, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3020208 parameters, 3020192 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/labels/train.cache... 207564 images, 0 backgrounds, 75 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 207564/207564 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/fly8_00101.jpg: ignoring corrupt image/label: negative label values [ -0.0012509]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/fly8_00185.jpg: ignoring corrupt image/label: negative label values [ -0.0029392]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/fly8_00186.jpg: ignoring corrupt image/label: negative label values [ -0.0023766]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/fly8_00188.jpg: ignoring corrupt image/label: negative label values [ -0.0012509]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/fly8_00189.jpg: ignoring corrupt image/label: negative label values [-0.00068796]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/fly8_00190.jpg: ignoring corrupt image/label: negative label values [-0.00012611]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet6_05638.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0265]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet6_05846.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0354]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet6_05847.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0265]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet6_05848.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0175]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet6_06799.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0354]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01384.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0108]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01385.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0229]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01386.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0314]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01387.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       1.04]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01388.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0485]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01389.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0382]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01392.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0122]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_01986.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0229]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_00086.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0108]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_00179.jpg: ignoring corrupt image/label: negative label values [ -0.0010649]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_00292.jpg: ignoring corrupt image/label: negative label values [ -0.0015714]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_00342.jpg: ignoring corrupt image/label: negative label values [ -0.0078312]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01034.jpg: ignoring corrupt image/label: negative label values [  -0.015013]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01126.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0066]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01280.jpg: ignoring corrupt image/label: negative label values [  -0.006039]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01567.jpg: ignoring corrupt image/label: negative label values [ -0.0015714]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01588.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0243]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01613.jpg: ignoring corrupt image/label: negative label values [ -0.0096234]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01662.jpg: ignoring corrupt image/label: negative label values [ -0.0045455]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01664.jpg: ignoring corrupt image/label: negative label values [  -0.011532]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01665.jpg: ignoring corrupt image/label: negative label values [  -0.015013]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01766.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.017]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01769.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0145]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01770.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0104]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01771.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0063]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01772.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0021]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01853.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01854.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0137]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01855.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0108]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01856.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0078]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_01857.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0048]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02416.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02534.jpg: ignoring corrupt image/label: negative label values [  -0.006039]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02535.jpg: ignoring corrupt image/label: negative label values [ -0.0066364]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02536.jpg: ignoring corrupt image/label: negative label values [ -0.0072338]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02537.jpg: ignoring corrupt image/label: negative label values [ -0.0078312]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02538.jpg: ignoring corrupt image/label: negative label values [ -0.0084286]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02539.jpg: ignoring corrupt image/label: negative label values [  -0.009026]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02540.jpg: ignoring corrupt image/label: negative label values [ -0.0096234]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02541.jpg: ignoring corrupt image/label: negative label values [  -0.010221]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02543.jpg: ignoring corrupt image/label: negative label values [  -0.011416]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02544.jpg: ignoring corrupt image/label: negative label values [  -0.012013]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02588.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0062]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02595.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0102]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02596.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0066]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02597.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.003]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02777.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02778.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0062]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02779.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0098]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02780.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0134]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02781.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.017]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02782.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0207]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02784.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0279]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02785.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0316]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02786.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0352]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02787.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0388]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02788.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0424]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02789.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0461]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02790.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0497]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02792.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0428]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02793.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0323]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02796.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       1.01]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo8_02942.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0316]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/yoyo9_00756.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/labels/val.cache... 41008 images, 0 backgrounds, 10 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41008/41008 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/jet6_05844.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0071]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/jet8_01391.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0254]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_00361.jpg: ignoring corrupt image/label: negative label values [ -0.0045455]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_01202.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0134]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_01470.jpg: ignoring corrupt image/label: negative label values [  -0.010221]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_01661.jpg: ignoring corrupt image/label: negative label values [ -0.0010649]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02245.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0104]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02783.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0243]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02795.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0112]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02952.jpg: ignoring corrupt image/label: negative label values [  -0.009026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      2.36G      2.106      5.636      1.096          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [20:25<00:00, 10.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:48<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.342      0.227      0.142     0.0752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      2.46G      2.056      2.208      1.084          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [19:05<00:00, 11.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:48<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.387      0.253      0.165     0.0916\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      2.46G      2.049      2.032      1.091          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:51<00:00, 11.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:45<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.428      0.228      0.166     0.0943\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      2.38G      1.988      1.901      1.078          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:47<00:00, 11.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:19<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.147     0.0245     0.0818     0.0457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      2.38G       1.88      1.717      1.047          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:44<00:00, 11.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:16<00:00, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998     0.0588     0.0056     0.0312     0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      2.37G      1.819      1.623       1.03          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:43<00:00, 11.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:17<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.131     0.0145     0.0708     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      2.37G      1.791      1.568      1.019          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:40<00:00, 11.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:24<00:00, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.314      0.101      0.189       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      2.35G      1.751      1.518      1.007          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:39<00:00, 11.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:35<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.181      0.272      0.194      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20       2.4G      1.724      1.476      1.001          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:38<00:00, 11.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:44<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998       0.51      0.231      0.199      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      2.41G      1.696      1.443     0.9938          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:35<00:00, 11.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:46<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998       0.47      0.287      0.205      0.119\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      2.46G      1.722      1.464       1.02          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:24<00:00, 11.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.456      0.311      0.211      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      2.39G      1.687       1.42      1.011          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:25<00:00, 11.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.437      0.328      0.214      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      2.42G      1.664      1.388      1.004          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:25<00:00, 11.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.419      0.338      0.217      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      2.43G      1.635      1.356     0.9953          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:24<00:00, 11.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.424      0.342      0.218      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      2.42G      1.605      1.323     0.9882          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:28<00:00, 11.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:46<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.446      0.348       0.22      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20       2.4G      1.571      1.287     0.9785          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:28<00:00, 11.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.433      0.354      0.223      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      2.43G      1.543      1.259     0.9728          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:28<00:00, 11.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:46<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.431      0.359      0.226      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      2.43G      1.509      1.227      0.964          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:26<00:00, 11.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.435      0.359      0.228      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      2.42G      1.469      1.188     0.9565          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:26<00:00, 11.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.434      0.365       0.23      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20       2.4G      1.427      1.149     0.9461          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12969/12969 [18:26<00:00, 11.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:47<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.441      0.367      0.233      0.138\n",
      "\n",
      "20 epochs completed in 6.794 hours.\n",
      "Optimizer stripped from /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.12 ðŸš€ Python-3.10.12 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 7952MiB)\n",
      "Model summary (fused): 168 layers, 3015008 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1282/1282 [01:42<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.441      0.367      0.233      0.138\n",
      "              aircraft      40998       1429      0.507      0.512      0.304      0.219\n",
      "                   ant      40998       1876      0.345      0.378      0.228      0.119\n",
      "             badminton      40998        747      0.428      0.201      0.152     0.0632\n",
      "                  bait      40998         33      0.369      0.394      0.203     0.0729\n",
      "               balloon      40998        991      0.303      0.187      0.112     0.0593\n",
      "                   bat      40998        147          1          0    0.00595    0.00131\n",
      "                   bee      40998        460      0.555       0.58      0.415      0.241\n",
      "                  bery      40998         33          0          0          0          0\n",
      "               bicycle      40998       1484      0.431      0.225      0.156     0.0917\n",
      "                  bird      40998       1894      0.315       0.21      0.131     0.0673\n",
      "                  boat      40998        415       0.39      0.605      0.374      0.245\n",
      "               bowling      40998        314      0.483      0.532      0.308      0.187\n",
      "         bronze_statue      40998        112      0.505      0.509      0.306      0.215\n",
      "                   car      40998       4202      0.311      0.262      0.156     0.0875\n",
      "                 chick      40998         79      0.597      0.618      0.518      0.351\n",
      "                  dice      40998        211      0.517      0.531      0.358      0.264\n",
      "            drosophila      40998        116      0.247     0.0765     0.0331     0.0124\n",
      "                 eagle      40998        318       0.58      0.566       0.36      0.264\n",
      "      electric_bicycle      40998        486      0.331      0.187      0.126     0.0606\n",
      "                  fish      40998        345      0.383      0.461      0.251       0.14\n",
      "                   fly      40998        643      0.476      0.465      0.324      0.199\n",
      "                  golf      40998        265      0.536      0.415      0.308      0.151\n",
      "                hoodle      40998       2163      0.324       0.36      0.167     0.0699\n",
      "                insect      40998        774      0.574      0.574      0.378      0.243\n",
      "                   jet      40998       3363      0.512      0.467       0.29      0.189\n",
      "                  kite      40998        828       0.25      0.297      0.153     0.0715\n",
      "      Kongming_Lantern      40998        822      0.285      0.343      0.178      0.098\n",
      "              ladybird      40998        835      0.562      0.551       0.37      0.257\n",
      "                 light      40998        124          1          0      0.037    0.00757\n",
      "                meteor      40998         36      0.393      0.167      0.146      0.068\n",
      "                  moon      40998         62      0.574      0.581      0.397      0.289\n",
      "            Paraglider      40998        454      0.501      0.441      0.291      0.133\n",
      "                people      40998       3424      0.342      0.398      0.218      0.123\n",
      "              pingpang      40998       1190      0.482      0.352      0.227      0.109\n",
      "             poker_box      40998        328      0.492      0.506      0.306      0.192\n",
      "                 sheep      40998        188      0.347      0.399      0.218      0.107\n",
      "                  shot      40998        113       0.31      0.147      0.107      0.044\n",
      "                shrimp      40998        306       0.56      0.618      0.413      0.331\n",
      "           shuttlecock      40998       1840      0.457      0.267      0.166     0.0719\n",
      "            skateboard      40998        272      0.328      0.279      0.141     0.0807\n",
      "            snake_head      40998        275      0.401      0.452      0.273      0.171\n",
      "                soccer      40998       1455      0.462      0.388      0.231      0.116\n",
      "                  star      40998       1085      0.442      0.267      0.249      0.136\n",
      "               surfing      40998        430      0.334      0.544      0.271      0.164\n",
      "                tennis      40998       2349      0.333      0.117     0.0734     0.0232\n",
      "                   ufo      40998         45      0.505      0.578      0.364      0.204\n",
      "            volleyball      40998        603      0.484       0.38      0.217      0.148\n",
      "                  yoyo      40998       1034       0.33      0.235      0.167     0.0822\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train18\u001b[0m\n",
      "Ultralytics YOLOv8.2.12 ðŸš€ Python-3.10.12 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070, 7952MiB)\n",
      "Model summary (fused): 168 layers, 3015008 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/labels/val.cache... 41008 images, 0 backgrounds, 10 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41008/41008 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/jet6_05844.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0071]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/jet8_01391.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0254]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_00361.jpg: ignoring corrupt image/label: negative label values [ -0.0045455]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_01202.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0134]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_01470.jpg: ignoring corrupt image/label: negative label values [  -0.010221]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_01661.jpg: ignoring corrupt image/label: negative label values [ -0.0010649]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02245.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0104]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02783.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0243]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02795.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0112]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/val/yoyo8_02952.jpg: ignoring corrupt image/label: negative label values [  -0.009026]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2563 [00:00<?, ?it/s]/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2563/2563 [02:02<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      40998      40998      0.441      0.367      0.233      0.139\n",
      "              aircraft      40998       1429      0.506      0.511      0.303       0.22\n",
      "                   ant      40998       1876      0.344       0.38      0.228      0.119\n",
      "             badminton      40998        747      0.424      0.201      0.151     0.0653\n",
      "                  bait      40998         33      0.341      0.364      0.181     0.0685\n",
      "               balloon      40998        991      0.304      0.188      0.111     0.0613\n",
      "                   bat      40998        147          1          0    0.00531    0.00119\n",
      "                   bee      40998        460      0.553       0.58      0.415      0.241\n",
      "                  bery      40998         33          0          0          0          0\n",
      "               bicycle      40998       1484      0.426      0.224      0.155     0.0925\n",
      "                  bird      40998       1894      0.314       0.21      0.131      0.068\n",
      "                  boat      40998        415      0.391      0.605      0.376      0.252\n",
      "               bowling      40998        314      0.482      0.532      0.308      0.187\n",
      "         bronze_statue      40998        112      0.505      0.509      0.306      0.216\n",
      "                   car      40998       4202      0.309      0.262      0.156     0.0883\n",
      "                 chick      40998         79      0.585      0.606      0.506      0.353\n",
      "                  dice      40998        211      0.517      0.531      0.358      0.265\n",
      "            drosophila      40998        116      0.247     0.0766     0.0334     0.0122\n",
      "                 eagle      40998        318       0.58      0.566      0.362      0.266\n",
      "      electric_bicycle      40998        486      0.329      0.187      0.126     0.0604\n",
      "                  fish      40998        345      0.385      0.464      0.251      0.139\n",
      "                   fly      40998        643      0.476      0.465      0.324        0.2\n",
      "                  golf      40998        265       0.54      0.419       0.31      0.153\n",
      "                hoodle      40998       2163      0.323      0.359      0.165     0.0704\n",
      "                insect      40998        774      0.572      0.574      0.378      0.243\n",
      "                   jet      40998       3363      0.513      0.468       0.29       0.19\n",
      "                  kite      40998        828      0.248      0.296      0.153     0.0719\n",
      "      Kongming_Lantern      40998        822      0.284      0.342      0.178     0.0986\n",
      "              ladybird      40998        835      0.563      0.552      0.371      0.257\n",
      "                 light      40998        124          1          0     0.0518     0.0104\n",
      "                meteor      40998         36      0.393      0.167      0.146     0.0635\n",
      "                  moon      40998         62      0.574      0.581      0.395      0.297\n",
      "            Paraglider      40998        454      0.507      0.447      0.295      0.135\n",
      "                people      40998       3424      0.342      0.399      0.219      0.124\n",
      "              pingpang      40998       1190      0.482      0.351      0.227       0.11\n",
      "             poker_box      40998        328      0.494      0.509      0.308      0.194\n",
      "                 sheep      40998        188      0.352      0.399       0.22      0.108\n",
      "                  shot      40998        113      0.314       0.15      0.107     0.0456\n",
      "                shrimp      40998        306      0.559      0.618      0.414      0.329\n",
      "           shuttlecock      40998       1840      0.457      0.266      0.166     0.0726\n",
      "            skateboard      40998        272      0.328      0.279      0.141     0.0811\n",
      "            snake_head      40998        275      0.403      0.451      0.274      0.172\n",
      "                soccer      40998       1455      0.462      0.388      0.231      0.117\n",
      "                  star      40998       1085      0.442      0.268       0.25       0.14\n",
      "               surfing      40998        430      0.336      0.544      0.271      0.164\n",
      "                tennis      40998       2349      0.328      0.115     0.0731     0.0233\n",
      "                   ufo      40998         45      0.504      0.578      0.364      0.208\n",
      "            volleyball      40998        603      0.483       0.38      0.218      0.149\n",
      "                  yoyo      40998       1034      0.329       0.24      0.168     0.0829\n",
      "Speed: 0.1ms preprocess, 1.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/coinse/Documents/lm/spring2024/CS570-Video-Classification/runs/detect/train182\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "# results = model.train(data='coco8.yaml', epochs=3)  # train the model\n",
    "# results = model.train(data=os.path.abspath('datasets/ToT_extracted/ToT.yaml'), epochs=1)  # train the model\n",
    "results = model.train(data=os.path.abspath('datasets/TOT/TOT.yaml'), epochs=20)  # train the model\n",
    "results = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/coinse/Documents/lm/spring2024/CS570-Video-Classification/datasets/TOT/YOLO/images/train/jet8_00001.jpg: 384x640 1 jet, 104.1ms\n",
      "Speed: 2.5ms preprocess, 104.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "ex_image = 'datasets/TOT/YOLO/images/train/jet8_00001.jpg'\n",
    "results = model(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
